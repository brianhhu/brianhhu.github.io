---
layout: page
title: Research
subtitle: These are the projects I have worked on...
published: true
---
**Bayesian Object Recognition**
<img style="float: right;" src="http://brianhhu.github.io/img/Fig_BIAS.png" width="250">

During visual perception of complex objects, humans shift their gaze to different regions of a particular object in order to gain more information about that object. We propose a parts-based, Bayesian framework for integrating information across receptive fields and fixation locations in order to recognize objects.

Code | Report

**Head Movements in Virtual Reality**
<img style="float: right;" src="http://brianhhu.github.io/img/Fig_Head.png" width="250">

Covert visual attention is traditionally studied using eye movements under head-fixed conditions. Here, we study the role of head movements when viewing large-scale, immersive natural images in virtual reality. We quantify head movement kinematics under these conditions and show that head movements follow a stereotyped pattern.

Data | Paper

**Figure-Ground Segmentation in Natural Images**
<img style="float: right;" src="http://brianhhu.github.io/img/Fig_FG.png" width="250">

Figure-ground segmentation is essential for understanding natural scenes. However, the neural mechanisms of this process are unclear. We propose an image computable model that performs both contour detection and figure-ground segmentation on natural images. We use the Berkeley Segmentation Dataset (BSDS-300) to evaluate our results.

Code | Abstract

**Contour Integration and Border Ownership Assignment**
<img style="float: right;" src="http://brianhhu.github.io/img/Fig_Contour.png" width="250">

We propose a recurrent neural model that reproduces several sets of experimental results related to contour integration and border ownership assignment using the same network parameters. Our model also provides testable predictions about the role of feedback and attention in different visual areas.

Code | Paper

**3D Visual Saliency**
<img style="float: right;" src="http://brianhhu.github.io/img/Fig_3DSaliency.png" width="250">

We extend a previous model of proto-object based saliency to include depth information. Our results show that the added depth information provides a small, but statistically significant improvement in gaze prediction on three separate eye tracking datasets.

Code | [Paper](http://brianhhu.github.io/files/Hu_etal16_3DSaliency.pdf)

**3D Surface Representation**
<img style="float: right;" src="http://brianhhu.github.io/img/Fig_3DSurface.png" width="250">

How the brain represents 3D surfaces and directs attention to these surfaces is not well known. We propose a neural model that groups together the disparity-selective neurons that belong to a surface. Our model also reproduces several psychophysical results related to the spread of attention across surfaces.

Code | [Paper](http://brianhhu.github.io/files/Hu_etal15_3DSurface.pdf)

I can also be found on [Google Scholar](https://scholar.google.com/citations?user=JNkLR8kAAAAJ&hl=en).
