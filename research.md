---
layout: page
title: Research
subtitle: These are the projects I have worked on...
published: true
---
**Bayesian Object Recognition**
<img style="float: right;" src="http://brianhhu.github.io/img/Fig_BIAS.png" width="250">

During visual perception of complex objects, humans shift their gaze to different regions of a particular object in order to gain more information about that object. We propose a parts-based, Bayesian framework for integrating information across receptive fields and fixation locations in order to recognize objects.

Code | [Report](http://brianhhu.github.io/files/Hu_BIAS_Report.pdf)

**Figure-Ground Segmentation in Natural Images**
<img style="float: right;" src="http://brianhhu.github.io/img/Fig_FG.png" width="250">

Figure-ground segmentation is essential for understanding natural scenes. However, the neural mechanisms of this process remain unclear. We propose a fully image computable model that performs both contour detection and figure-ground segmentation on natural images. We compare our model results to the responses of border-ownership selective neurons and also evaluate our model using the Berkeley Segmentation Dataset (BSDS-300).

Code | [Abstract](http://brianhhu.github.io/files/Hu_COSYNE_Abstract.pdf)

**Contour Integration and Border-Ownership Assignment**
<img style="float: right;" src="http://brianhhu.github.io/img/Fig_Contour.png" width="250">

We propose a recurrent neural model that explains several sets of neurophysiological results related to contour integration and border ownership assignment using the same network parameters. Our model also provides testable predictions about the role of feedback and attention in different visual areas.

[Code](https://github.com/brianhhu/Contour_BOS) | [Paper](http://brianhhu.github.io/files/Hu_Niebur17.pdf)

**Head Movements in Virtual Reality**
<img style="float: right;" src="http://brianhhu.github.io/img/Fig_Head.png" width="250">

Natural visual exploration makes use of both head movements and eye movements. Here, we study the role of head movements when viewing large-scale, immersive images in virtual reality. We quantify head movement kinematics under these conditions and show that head movements follow a stereotyped pattern.

[Code/Data](https://github.com/brianhhu/VR_HeadMovements) | [Paper](http://brianhhu.github.io/files/Hu_etal17_HeadMovements.pdf)

**3D Visual Saliency**
<img style="float: right;" src="http://brianhhu.github.io/img/Fig_3DSaliency.png" width="250">

We extend a model of proto-object based saliency to include depth information. Our results show that the added depth information provides a small, but statistically significant improvement in gaze prediction on three separate eye tracking datasets.

[Code](https://github.com/brianhhu/3D-Saliency) | [Paper](http://brianhhu.github.io/files/Hu_etal16_3DSaliency.pdf)

**3D Surface Representation**
<img style="float: right;" src="http://brianhhu.github.io/img/Fig_3DSurface.png" width="250">

How the brain represents 3D surfaces and directs attention to these surfaces is not well known. We propose a neural model that groups together disparity-selective neurons that belong to a surface. Our model is also able to reproduce several key psychophysical results, including the spread of attention across surfaces.

[Code](https://github.com/brianhhu/3D-Surface-Grouping) | [Paper](http://brianhhu.github.io/files/Hu_etal15_3DSurface.pdf)

<br><br>
I can also be found on [Google Scholar](https://scholar.google.com/citations?user=JNkLR8kAAAAJ&hl=en).
